# -*- coding: utf-8 -*-
"""Netflix_Movie_popularity_Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eM8neM1vXnU1kyRw5A4QR7wG-lK3872c
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Optional for better visuals
sns.set(style="darkgrid")

titles = pd.read_csv('titles.csv')
credits = pd.read_csv('credits.csv')

print("Titles:\n", titles.head())
print("\nCredits:\n", credits.head())

print("Titles Info:")
titles.info()

print("\nCredits Info:")
credits.info()

print("Titles shape:", titles.shape)
print("Credits shape:", credits.shape)

print("Titles Dataset:")
display(titles.head())

print("\nCredits Dataset:")
display(credits.head())

# Merge datasets on the 'id' column (title ID)
merged_df = pd.merge(titles, credits, on='id')

# Show the first few rows
merged_df.head()

# Overview of merged dataset
print("Merged DataFrame shape:", merged_df.shape)

# Show column data types and non-null counts
merged_df.info()

# Check for missing values
print("\nMissing values:\n", merged_df.isnull().sum())

# Drop row with missing title
merged_df = merged_df.dropna(subset=['title'])

# Fill missing 'description' with 'No description'
merged_df['description'] = merged_df['description'].fillna('No description')

# Fill missing 'age_certification' with 'Unrated'
merged_df['age_certification'] = merged_df['age_certification'].fillna('Unrated')

# Fill missing 'tmdb_score' and 'imdb_score' with their respective mean values
merged_df['tmdb_score'] = merged_df['tmdb_score'].fillna(merged_df['tmdb_score'].mean())
merged_df['imdb_score'] = merged_df['imdb_score'].fillna(merged_df['imdb_score'].mean())

# Optionally fill missing 'character' as 'Unknown'
merged_df['character'] = merged_df['character'].fillna('Unknown')

# Get unique movies with max popularity
unique_movies = merged_df[merged_df['type'] == 'MOVIE'].groupby('title')['tmdb_popularity'].max().reset_index()

# Sort by popularity descending
top_popular_unique = unique_movies.sort_values(by='tmdb_popularity', ascending=False)

top_popular_unique.head(10)

plt.figure(figsize=(10,6))
sns.histplot(merged_df[merged_df['type'] == 'MOVIE']['runtime'], bins=30, kde=True)
plt.title('Distribution of Movie Runtimes')
plt.xlabel('Runtime (minutes)')
plt.show()

# Convert string lists to actual lists
import ast

merged_df['production_countries'] = merged_df['production_countries'].apply(ast.literal_eval)

# Explode the lists so each country has its own row
countries_exploded = merged_df.explode('production_countries')

# Count content per country
country_counts = countries_exploded['production_countries'].value_counts().reset_index()
country_counts.columns = ['Country', 'Count']

# Show top 10 countries by content count
print(country_counts.head(10))

# Plot
plt.figure(figsize=(12,6))
sns.barplot(data=country_counts.head(10), x='Country', y='Count')
plt.title('Top 10 Countries by Netflix Content Count')
plt.show()

# Convert genre strings to lists
merged_df['genres'] = merged_df['genres'].apply(ast.literal_eval)

# Explode genres so each genre has its own row
genres_exploded = merged_df.explode('genres')

# Count content per genre
genre_counts = genres_exploded['genres'].value_counts().reset_index()
genre_counts.columns = ['Genre', 'Count']

# Show top 10 genres
print(genre_counts.head(10))

# Plot
plt.figure(figsize=(12,6))
sns.barplot(data=genre_counts.head(10), x='Genre', y='Count')
plt.title('Top 10 Netflix Content Genres')
plt.xticks(rotation=45)
plt.show()

# Explode genres for individual analysis
genres_exploded = merged_df.explode('genres')

# Group by genre to get count and average IMDb score
genre_stats = genres_exploded.groupby('genres').agg({
    'title': 'count',           # count of movies per genre
    'imdb_score': 'mean'        # average IMDb score per genre
}).rename(columns={'title': 'Count', 'imdb_score': 'Avg_IMDb_Score'}).reset_index()

# Plot: count vs average IMDb score per genre
plt.figure(figsize=(12,6))
sns.scatterplot(data=genre_stats, x='Count', y='Avg_IMDb_Score', hue='genres', s=100)
plt.title('Genre Popularity (Count) vs Average IMDb Score')
plt.xlabel('Number of Titles (Count)')
plt.ylabel('Average IMDb Score')
plt.legend(title='Genre', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()

# Filter only movies (exclude shows)
movies_df = merged_df[merged_df['type'] == 'MOVIE'].copy()

# Create binary target: Popular (1) if imdb_score >= 7.0, else Not popular (0)
movies_df['popular'] = (movies_df['imdb_score'] >= 7.0).astype(int)

# Select features to use
# Let's use: runtime, tmdb_popularity, tmdb_score, genres (we will one-hot encode genres)

# One-hot encode genres
genres_onehot = movies_df['genres'].explode().str.get_dummies().groupby(level=0).max()

# Combine features
X = pd.concat([movies_df[['runtime', 'tmdb_popularity', 'tmdb_score']], genres_onehot], axis=1)

y = movies_df['popular']

print(f"Features shape: {X.shape}, Labels shape: {y.shape}")

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

import pandas as pd
import ast

# Load your datasets again (change paths or upload as needed)
titles = pd.read_csv('titles.csv')   # or your path to titles file
credits = pd.read_csv('credits.csv') # or your path to credits file

# Merge on 'id' column
merged_df = pd.merge(titles, credits, on='id', how='left')

# Convert 'genres' column strings to lists
merged_df['genres'] = merged_df['genres'].apply(ast.literal_eval)

# Filter only movies
movies_df = merged_df[merged_df['type'] == 'MOVIE'].copy()

# One-hot encode genres
genres_onehot = movies_df['genres'].explode().str.get_dummies().groupby(level=0).max()

# Remove duplicate titles to keep only unique movies
unique_movies_df = sample_movies_df.drop_duplicates(subset='title').copy()

# Re-create genres_onehot for unique movies
genres_onehot_unique = unique_movies_df['genres'].explode().str.get_dummies().groupby(level=0).max()

# Recompute similarity matrix
cos_sim_unique = cosine_similarity(genres_onehot_unique)

cos_sim_df_unique = pd.DataFrame(cos_sim_unique, index=unique_movies_df.index, columns=unique_movies_df.index)

# Updated recommendation function
def recommend_movies_unique(movie_title, top_n=5):
    matches = unique_movies_df[unique_movies_df['title'].str.lower() == movie_title.lower()]
    if matches.empty:
        return f"No movie found with title '{movie_title}' in unique dataset."
    idx = matches.index[0]
    sim_scores = cos_sim_df_unique.loc[idx].drop(idx)
    top_indices = sim_scores.nlargest(top_n).index
    return unique_movies_df.loc[top_indices, 'title'].values

# Test the fixed recommendation
print(recommend_movies_unique("Taxi Driver", top_n=5))

def recommend_movies_filtered(movie_title, top_n=5, popularity_weight=0.5, rating_weight=0.5):
    matches = unique_movies_df[unique_movies_df['title'].str.lower() == movie_title.lower()]
    if matches.empty:
        return f"No movie found with title '{movie_title}' in unique dataset."

    idx = matches.index[0]
    sim_scores = cos_sim_df_unique.loc[idx].drop(idx)

    # Normalize popularity and rating columns to [0,1]
    pop_norm = (unique_movies_df['tmdb_popularity'] - unique_movies_df['tmdb_popularity'].min()) / (unique_movies_df['tmdb_popularity'].max() - unique_movies_df['tmdb_popularity'].min())
    rating_norm = (unique_movies_df['imdb_score'] - unique_movies_df['imdb_score'].min()) / (unique_movies_df['imdb_score'].max() - unique_movies_df['imdb_score'].min())

    # Calculate combined score: similarity + weighted popularity + weighted rating
    combined_score = sim_scores + popularity_weight * pop_norm + rating_weight * rating_norm

    # Select top movies by combined score
    top_indices = combined_score.nlargest(top_n).index

    return unique_movies_df.loc[top_indices, ['title', 'tmdb_popularity', 'imdb_score']]

recommend_movies_filtered("Taxi Driver", top_n=5)

from sklearn.preprocessing import MinMaxScaler

# Normalize runtime and release_year
scaler = MinMaxScaler()
unique_movies_df['runtime_norm'] = scaler.fit_transform(unique_movies_df[['runtime']])
unique_movies_df['release_year_norm'] = scaler.fit_transform(unique_movies_df[['release_year']])

# Combine genre one-hot vectors with normalized numeric features
features = genres_onehot_unique.copy()
features['runtime_norm'] = unique_movies_df['runtime_norm']
features['release_year_norm'] = unique_movies_df['release_year_norm']
features['tmdb_popularity'] = unique_movies_df['tmdb_popularity'].fillna(0)

# Compute cosine similarity on combined features
cos_sim_multi = cosine_similarity(features)
cos_sim_multi_df = pd.DataFrame(cos_sim_multi, index=unique_movies_df.index, columns=unique_movies_df.index)

def recommend_movies_multifeature(movie_title, top_n=5):
    matches = unique_movies_df[unique_movies_df['title'].str.lower() == movie_title.lower()]
    if matches.empty:
        return f"No movie found with title '{movie_title}'."
    idx = matches.index[0]
    sim_scores = cos_sim_multi_df.loc[idx].drop(idx)
    top_indices = sim_scores.nlargest(top_n).index
    return unique_movies_df.loc[top_indices, ['title', 'runtime', 'release_year', 'tmdb_popularity']]

recommend_movies_multifeature("Taxi Driver", top_n=5)

def interactive_recommender():
    while True:
        movie = input("Enter a movie title (or type 'exit' to quit): ").strip()
        if movie.lower() == 'exit':
            print("Exiting recommendation system.")
            break

        print("\nTop 5 recommendations based on genres + popularity + ratings:")
        recs = recommend_movies_filtered(movie, top_n=5)
        if isinstance(recs, str):  # Means no movie found
            print(recs)
        else:
            print(recs.to_string(index=False))

        print("\nTop 5 recommendations based on multi-feature similarity:")
        recs2 = recommend_movies_multifeature(movie, top_n=5)
        if isinstance(recs2, str):
            print(recs2)
        else:
            print(recs2.to_string(index=False))
        print("\n" + "-"*50 + "\n")

# Run this to start
interactive_recommender()